{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make synthetic data from synthetics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This Jupyter Notebook should be run in /project_name/source_name. It expects a stationlist.csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to calculate the kernels. To do this, observed correlation data is necessary. This script creates synthetic data from previously calculated synthetics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import obspy\n",
    "import pandas as pd\n",
    "from obspy import read\n",
    "from obspy.geodetics import gps2dist_azimuth\n",
    "import numpy as np\n",
    "import sys\n",
    "from glob import glob\n",
    "from obspy.core import AttribDict\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dataless conversion set it to true\n",
    "dataless = True\n",
    "corr_filt_sectionplot = True\n",
    "\n",
    "# Get Project name\n",
    "project_name = os.path.basename(os.path.dirname(os.getcwd()))\n",
    "# print(project_name)\n",
    "\n",
    "# first get paths to different files\n",
    "path_stations = ('../stationlist.csv')\n",
    "path_model = ('./step_0/corr/')\n",
    "path_obs = ('./observed_correlations/')\n",
    "\n",
    "\n",
    "# ABOVE CAN BE CHANGED FOR PYTHON SCRIPT TO RUN WITH INPUT ARGUMENTS, see Laura's code\n",
    "if dataless:\n",
    "# delete files in observed_correlations folder if necessary\n",
    "    for files in glob(os.path.join(path_obs,'*')):\n",
    "        os.remove(files)\n",
    "\n",
    "# copy files from the synthetic correlations to the observed correlations '/Source_1/observed_correlations/'\n",
    "    for files in glob(os.path.join(path_model,'*.sac')):\n",
    "            shutil.copy(files,path_obs)\n",
    "            print 'Copied:',files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename files as noisi expects different filename\n",
    "\n",
    "for filename in glob(os.path.join(path_obs,'*.sac*')):\n",
    "    # make sure they're not renamed if they've already been renamed\n",
    "    if filename.endswith(project_name + '.sac'): \n",
    "        break\n",
    "    else:\n",
    "        # get filename without extension\n",
    "        filename_wo_ext = os.path.splitext(filename)[0]\n",
    "        ext = os.path.splitext(filename)[1]\n",
    "        # change -- to . and add project name and extension\n",
    "        filename_1 = filename_wo_ext.replace('--','.')\n",
    "        filename_2 = filename_1 + '.' + project_name + ext\n",
    "        # rename the file\n",
    "        os.rename(filename,filename_2)\n",
    "        print 'Renamed:', filename_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check metadata in observed_correlations folder\n",
    "# load the correlations into a file with obspy\n",
    "ext = '*.sac'\n",
    "corrs_path_obs = os.path.join(path_obs,ext) # get all .sac files in directory\n",
    "st = obspy.read(corrs_path_obs) # load all into one stream\n",
    "# print(st)\n",
    "print st[0].stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign Geodata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changed the indir and metafile input so it would run in this notebook. \n",
    "For meta = .. engine = 'python' has been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indir = sys.argv[1]\n",
    "#metafile = sys.argv[2]\n",
    "indir = path_obs\n",
    "metafile = '../stationlist.csv'\n",
    "\n",
    "\n",
    "print(indir)\n",
    "traces = glob(indir+'/*.SAC')\n",
    "traces.extend(glob(indir+'/*.sac'))\n",
    "print('Found traces:\\n')\n",
    "print(traces[0])\n",
    "print('...to...')\n",
    "print(traces[-1])\n",
    "print('\\n')\n",
    "print('Assign geographical information.\\n')\n",
    "print('Number of traces:')\n",
    "print(np.size(traces))\n",
    "print('\\n')\n",
    "\n",
    "meta = pd.read_csv(metafile, engine='python')\n",
    "\n",
    "for t in traces:\n",
    "    tr = read(t)\n",
    "    sta1 = os.path.basename(t).split('.')[1]\n",
    "    try:\n",
    "        sta2 = os.path.basename(t).split('--')[1].split('.')[1]\n",
    "    except IndexError:\n",
    "        sta2 = os.path.basename(t).split('.')[5]\n",
    "    print(sta1,sta2)\n",
    "    lat1 = float(meta[meta['sta']==sta1].iloc[0]['lat'])\n",
    "    lat2 = float(meta[meta['sta']==sta2].iloc[0]['lat'])\n",
    "    lon1 = float(meta[meta['sta']==sta1].iloc[0]['lon'])\n",
    "    lon2 = float(meta[meta['sta']==sta2].iloc[0]['lon'])\n",
    "    print(lat1,lon1,lat2,lon2)\n",
    "    \n",
    "    tr[0].stats.network = os.path.basename(t).split('.')[0]\n",
    "    tr[0].stats.station = sta1\n",
    "    tr[0].stats.location = ''\n",
    "    tr[0].stats.channel = os.path.basename(t).split('.')[3] #os.path.basename(t).split('.')[3].split('--')[0]\n",
    "    tr[0].stats.sac.stlo = lon1\n",
    "    tr[0].stats.sac.stla = lat1\n",
    "    tr[0].stats.sac.evlo = lon2\n",
    "    tr[0].stats.sac.evla = lat2\n",
    "    tr[0].stats.sac.kuser0 = meta[meta['sta']==sta2].iloc[0]['net']\n",
    "    \n",
    "    tr[0].stats.sac.kevnm = sta2\n",
    "    tr[0].stats.sac.kuser1 = ''\n",
    "    try:\n",
    "        tr[0].stats.sac.kuser2 = os.path.basename(t).split('.')[7] #os.path.basename(t).split('--')[1].split('.')[3]\n",
    "    except IndexError:\n",
    "        sta2 = os.path.basename(t).split('.')[7]\n",
    "    tr[0].stats.sac.user0 = 100.   \n",
    "    #print lat1 > -90.\n",
    "    #print lat1 < 90.\n",
    "    #print type(lat1)\n",
    "    #print(float(lat1))\n",
    "    #print lat1,lon1,lat2,lon2\n",
    "    \n",
    "    geoinf = gps2dist_azimuth(lat1,lon1,lat2,lon2)\n",
    "    tr[0].stats.sac.dist = geoinf[0]\n",
    "    tr[0].stats.sac.az = geoinf[1]\n",
    "    tr[0].stats.sac.baz = geoinf[2]\n",
    "    tr[0].stats['distance'] = geoinf[0]   # add stats.distance for section plot\n",
    "    #print tr[0].stats.keys()\n",
    "\n",
    "    tr.write(t,format='SAC')\n",
    "    #tr.plot()\n",
    "    \n",
    "    #tr.plot(type='section',scale=150)\n",
    "    #print(tr[0].stats.distance)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting and filtering\n",
    "\n",
    "A bandpass filter is needed for the next steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the metadata again\n",
    "ext = '*.sac'\n",
    "corrs_path_obs = os.path.join(path_obs,ext) # get all .sac files in directory\n",
    "st = obspy.read(corrs_path_obs) # load all into one stream\n",
    "#print(st)\n",
    "print st[0].stats \n",
    "#print st[0].stats.distance\n",
    "st.plot(type='relative',reftime = st[0].stats.starttime + st[0].stats.delta*st[0].stats.npts/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandpass filter\n",
    "\n",
    "bandpass = [0.02,0.05,2] # freqmin, freqmax, corners\n",
    "\n",
    "filt_freqmin = bandpass[0]\n",
    "filt_freqmax = bandpass[1]\n",
    "filt_corners = bandpass[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section plot to visualise correlations if c\n",
    "if corr_filt_sectionplot: \n",
    "    st1 = obspy.Stream()\n",
    "    st2 = obspy.Stream()\n",
    "\n",
    "    for tr in traces:\n",
    "        t = read(tr)\n",
    "        t[0].stats.distance = t[0].stats.sac.dist\n",
    "        #print t[0].stats.distance\n",
    "        \n",
    "        # Change filter below\n",
    "        t_filt = t.copy()\n",
    "        t_filt.filter('bandpass',freqmin=filt_freqmin,freqmax=filt_freqmax,corners=filt_corners,zerophase = True)\n",
    "        st1 += t_filt\n",
    "        st2 += t\n",
    "\n",
    "    st1.plot(type='section',reftime = st1[0].stats.starttime + st1[0].stats.delta*st1[0].stats.npts/2)\n",
    "    st2.plot(type='section',reftime = st2[0].stats.starttime + st2[0].stats.delta*st2[0].stats.npts/2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: dataless measurement (dataless = True)\n",
    "\n",
    "All the traces are changed to 1 as if the measurement is 0. That means: synthetics are compared with synthetic data that is 1.\n",
    "\n",
    "\n",
    "\n",
    "## Option 2: Compare it to a different source distribution (dataless = False)\n",
    "\n",
    "For this, a second source distribution is used to calculate the adjoint source. All above steps are run but the trace.data is not changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all trace.data to 1 if dataless = true or leave\n",
    "print(st)\n",
    "\n",
    "if dataless:\n",
    "    for trace in st:\n",
    "        size = np.size(trace.data)\n",
    "        trace.data = np.ones(size)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "st.plot(type='relative',reftime = st[0].stats.starttime + st[0].stats.delta*st[0].stats.npts/2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Noisi_Py2]",
   "language": "python",
   "name": "conda-env-Noisi_Py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
